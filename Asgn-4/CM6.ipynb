{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1987d1c1",
   "metadata": {},
   "source": [
    "<h2><center>ASSIGNMENT 4</center></h2>\n",
    "<h2><center>DEEP ASHISH JARIWALA, JAYDEEP SINGH</center></h2>\n",
    "<h2><center>GROUP - 41</center></h2>\n",
    "<h2><center>Q: CM6</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680aa15e",
   "metadata": {},
   "source": [
    "<p>The following notebook provides a detailed comparsion of all the algorithms (with run time performance) applied to classify the fashion mnist. The following steps were followed to select the best model:</p>\n",
    "<ul>\n",
    "            <li>Testing different architecture for convolutional neural networks and selecting the best performing model in terms of accuracy and computation complexity</li>\n",
    "            <li>The selected model has many hyperparamaters like optimizers and activation functions.</li>\n",
    "            <li>The best selected model in terms of architecture is tuned for 3 different activation functions to get the best result</li>\n",
    "            <li>Then, the best tuned model from the above case is tuned for 3 different optimizers to get the best performing result</li>\n",
    "            <li>Once the optimizer and activation functions are selected the model is compared using different learning rates and regularization parameter to get the final model for classification</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ef371d",
   "metadata": {},
   "source": [
    "# SELECTION OF BEST ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de49d7e",
   "metadata": {},
   "source": [
    "### MODEL 1 GRAPHS AND SUMMARY (BEST PERFORMING MODEL USED IN CM4)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5548abf",
   "metadata": {},
   "source": [
    "Model: \"sequential_1\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_2 (Conv2D)            (None, 27, 27, 96)        480       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 96)        0         \n",
    "_________________________________________________________________\n",
    "batch_normalization_1 (Batch (None, 13, 13, 96)        384       \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 13, 13, 96)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 10, 10, 256)       393472    \n",
    "_________________________________________________________________\n",
    "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 6400)              0         \n",
    "_________________________________________________________________\n",
    "dense_4 (Dense)              (None, 512)               3277312   \n",
    "_________________________________________________________________\n",
    "dense_5 (Dense)              (None, 256)               131328    \n",
    "_________________________________________________________________\n",
    "dense_6 (Dense)              (None, 128)               32896     \n",
    "_________________________________________________________________\n",
    "dense_7 (Dense)              (None, 5)                 645       \n",
    "=================================================================\n",
    "Total params: 3,836,517\n",
    "Trainable params: 3,836,325\n",
    "Non-trainable params: 192\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292cf222",
   "metadata": {},
   "source": [
    "<img src = 'final_image_1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25993efc",
   "metadata": {},
   "source": [
    "<p>Overall, this is the best performing model that provides the best accuracy. It can be seen that validation line for accuracy achieves stability around 10 to 12 epochs. We have used early stopping (patiance of 5) as a part of training our model in order to determine the number of epochs required to have an accurate fit for the classification model. This architecture involves increasing the kernel size and the number of filters (to gain more features) as the layers progress towards fully connected dense network. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6183b8",
   "metadata": {},
   "source": [
    "### MODEL 2 GRAPHS AND SUMMARY"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f96da596",
   "metadata": {},
   "source": [
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d (Conv2D)              (None, 14, 14, 256)       1280      \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 4, 4, 96)          1204320   \n",
    "_________________________________________________________________\n",
    "max_pooling2d (MaxPooling2D) (None, 2, 2, 96)          0         \n",
    "_________________________________________________________________\n",
    "dropout (Dropout)            (None, 2, 2, 96)          0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 384)               0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 512)               197120    \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 256)               131328    \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 128)               32896     \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 5)                 645       \n",
    "=================================================================\n",
    "Total params: 1,567,589\n",
    "Trainable params: 1,567,589\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88a16f",
   "metadata": {},
   "source": [
    "<img src = 'final_image_2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd8059a",
   "metadata": {},
   "source": [
    "<p>Overall, It is a good performing model but when compared to the model_1 it has less accuracy and more loss. The training is stable but it lacks total trainable parameters and regularization layers to perform better. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ea8a3",
   "metadata": {},
   "source": [
    "### MODEL 3 GRAPHS AND SUMMARY "
   ]
  },
  {
   "cell_type": "raw",
   "id": "754bc399",
   "metadata": {},
   "source": [
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d (Conv2D)              (None, 27, 27, 32)        160       \n",
    "_________________________________________________________________\n",
    "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
    "_________________________________________________________________\n",
    "batch_normalization (BatchNo (None, 13, 13, 32)        128       \n",
    "_________________________________________________________________\n",
    "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 10, 10, 64)        32832     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
    "_________________________________________________________________\n",
    "batch_normalization_1 (Batch (None, 5, 5, 64)          256       \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 4, 4, 128)         32896     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 512)               262656    \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 256)               131328    \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 128)               32896     \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 5)                 645       \n",
    "=================================================================\n",
    "Total params: 493,797\n",
    "Trainable params: 493,605\n",
    "Non-trainable params: 192\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd7cad0",
   "metadata": {},
   "source": [
    "<img src = 'm3cnn.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb03a43",
   "metadata": {},
   "source": [
    "<p>Overall, this is the worst performing model that provides the least accuracy. This model has very less number of filters and less kernel size to extract more features useful in determining an appropriate classification. It has 493,797 paramters which is 10 times less than the best performing model. Moreover, it has a poor performance in case of average validation accuracy although it was trained for a patience of 10 in early stopping algorithm compared to the best performing model which was trained at a patience of 5.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5d959",
   "metadata": {},
   "source": [
    "<p>The table below shows the performance metrics for all the architectures of convolutional neural networks. The dataset used was splitted in 80-10-10% ratio. 80% of the data is used for training, 10% validation and 10% completely unknown test set. The following results were obtained by different architecture:</p>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>MODEL</th>\n",
    "    <th>COVN2D</th>\n",
    "    <th>Filters and maxpool2d</th>\n",
    "    <th>PARAMETERS</th>\n",
    "    <th>OPTIMIZER and ACTIVATION</th>\n",
    "    <th>MEAN TRAINNG ACCURACY</th>\n",
    "    <th>MEAN TRAINNG LOSS</th>\n",
    "    <th>MEAN VALIDATION ACCURACY</th>\n",
    "    <th>MEAN VALIDATION LOSS</th>\n",
    "    <th>TESTING ACCURACY</th>\n",
    "    <th>COMPUTATION COMPLEXITY</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>2 layers</td>\n",
    "    <td>96, 256 | 2 layers</td>\n",
    "    <td>3,836,517</td>\n",
    "    <td>ADAM and RELU</td>\n",
    "    <td>89.98%</td>\n",
    "    <td>25.63%</td>\n",
    "    <td>86.46%</td>\n",
    "    <td>63.50%</td>\n",
    "    <td>91.82%</td>\n",
    "    <td>14 epochs - 560s</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>2 layers</td>\n",
    "    <td>96, 256 | 1 layer</td>\n",
    "    <td>1,567,589</td>\n",
    "    <td>ADAM and RELU</td>\n",
    "    <td>87.68%</td>\n",
    "    <td>30.48%</td>\n",
    "    <td>87.67%</td>\n",
    "    <td>30.40%</td>\n",
    "    <td>31.41%</td>\n",
    "    <td>21 epochs - 1536s</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>3 layers</td>\n",
    "    <td>32, 64, 128 | 3 layers</td>\n",
    "    <td>493,797</td>\n",
    "    <td>ADAM and RELU</td>\n",
    "    <td>90.08%</td>\n",
    "    <td>24.41%</td>\n",
    "    <td>74.91%</td>\n",
    "    <td>63.24%</td>\n",
    "    <td>88.96%</td>\n",
    "    <td>22 epochs - 1012s</td>\n",
    "  </tr>\n",
    "    </table>\n",
    "<p>Based on the results it can be seen that model one has a better performance in terms of all the metrics. It is computationally less complex with a comparable or greater accuracy (comparable or less loss) than other convolutional neural network models. The model also has regularization parameters to avoid over fitting. The best way to improve the selected architecture is by tuning various hyperparamters.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d76f75",
   "metadata": {},
   "source": [
    "# SELECTION OF BEST ACTIVATION FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff53646",
   "metadata": {},
   "source": [
    "<p>The table below shows the change in performance metrics with respect to activation functions for the best model selected above (MODEL_1).</p>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>MODEL</th>\n",
    "    <th>ACTIVATION</th>\n",
    "    <th>MEAN TRAIN ACCURACY</th>\n",
    "    <th>MEAN TRAIN LOSS</th>\n",
    "    <th>MEAN VALIDATION ACCURACY</th>\n",
    "    <th>MEAN VALIDATION LOSS</th>\n",
    "    <th>EPOCHS</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>relu</td>\n",
    "    <td>89.98%</td>\n",
    "    <td>25.63%</td>\n",
    "    <td>86.46%</td>\n",
    "    <td>63.50%</td>\n",
    "    <td>14</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>sigmoid</td>\n",
    "    <td>90.13%</td>\n",
    "    <td>25.34%</td>\n",
    "    <td>86.51%</td>\n",
    "    <td>63.89%</td>\n",
    "    <td>14</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>tanh</td>\n",
    "    <td>85.41%</td>\n",
    "    <td>36.99%</td>\n",
    "    <td>54.96%</td>\n",
    "    <td>176.08%</td>\n",
    "    <td>6</td>\n",
    "  </tr>\n",
    "    </table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b56aa8",
   "metadata": {},
   "source": [
    "<p> It can be seen that activations like relu has out perform other algorithms in terms of performance and computational complextity. A general problem with both the sigmoid and tanh functions is saturation meaning that large values snap to 1.0 and small values snap to -1 or 0 for tanh and sigmoid respectively. Furthermore, the functions are only really sensitive to changes around their mid-point of their input, such as 0.5 for sigmoid and 0.0 for tanh. Therefore, due to the limited sensitivity and saturation of the function happen regardless of whether the summed activation from the node provided as input contains useful information or not. Once saturated, it becomes challenging for the learning algorithm to continue to adapt the weights to improve the performance of the model.</p>\n",
    "<p>Relu rectifies the problem of vanishing gradiets and has many advantages over other metrics like (computational simplicity, representational sparsity, linear behaviour, able to train deep networks). All the statements can be justified using the performance in the classification problem.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc414a",
   "metadata": {},
   "source": [
    "# SELECTION OF BEST OPTIMIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a213be",
   "metadata": {},
   "source": [
    "<p>The table below shows the change in performance metrics with respect to optimizers for the best model selected above (MODEL_1).</p>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>MODEL</th>\n",
    "    <th>OPTIMIZER</th>\n",
    "    <th>MEAN TRAIN ACCURACY</th>\n",
    "    <th>MEAN TRAIN LOSS</th>\n",
    "    <th>MEAN VALIDATION ACCURACY</th>\n",
    "    <th>MEAN VALIDATION LOSS</th>\n",
    "    <th>EPOCHS</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Adam</td>\n",
    "    <td>89.98%</td>\n",
    "    <td>25.63%</td>\n",
    "    <td>86.46%</td>\n",
    "    <td>63.50%</td>\n",
    "    <td>14</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>RMSProp</td>\n",
    "    <td>20.10%</td>\n",
    "    <td>nan%</td>\n",
    "    <td>20.03%</td>\n",
    "    <td>nan%</td>\n",
    "    <td>5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>SGD</td>\n",
    "    <td>24.68%</td>\n",
    "    <td>708.2%</td>\n",
    "    <td>24.57%</td>\n",
    "    <td>710.77%</td>\n",
    "    <td>100</td>\n",
    "  </tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c742c7c",
   "metadata": {},
   "source": [
    "<p>Adam optimizer has the best performance compared to other optimization algorithms which either had a gradient explosion due to lack of heavy regularization or have a very high loss. Adam optimizer has many advantages over other optimizers primarily in terms of straight forward approach, computationally efficient and good in dealing with large amount of data. While training the model on SGD, it took a lot of time to get a minimia and optimize the classification solution. Moreover, the accuracy and loss obtained by SGD was not convinient showing that it is not a proper fit for this model and dataset.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c63357",
   "metadata": {},
   "source": [
    "<p>The best performing model has the following results:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63ebe1",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>MODEL</th>\n",
    "    <th>COVN2D</th>\n",
    "    <th>Filters and maxpool2d</th>\n",
    "    <th>PARAMETERS</th>\n",
    "    <th>OPTIMIZER and ACTIVATION</th>\n",
    "    <th>MEAN TRAINNG ACCURACY</th>\n",
    "    <th>MEAN TRAINNG LOSS</th>\n",
    "    <th>MEAN VALIDATION ACCURACY</th>\n",
    "    <th>MEAN VALIDATION LOSS</th>\n",
    "    <th>TESTING ACCURACY</th>\n",
    "    <th>COMPUTATION COMPLEXITY</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>2 layers</td>\n",
    "    <td>96, 256 | 2 layers</td>\n",
    "    <td>3,836,517</td>\n",
    "    <td>ADAM and RELU</td>\n",
    "    <td>89.98%</td>\n",
    "    <td>25.63%</td>\n",
    "    <td>86.46%</td>\n",
    "    <td>63.50%</td>\n",
    "    <td>91.82%</td>\n",
    "    <td>14 epochs - 560s</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
